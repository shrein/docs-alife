%%
%% neuralfields.tex
%% 
%% Made by jjfigueredou
%% Login   <jjfigueredou@fctp-jjfu>
%% 
%% Started on  Sun Oct  5 12:26:22 2008 jjfigueredou
%% Last update Sun Oct  5 12:26:22 2008 jjfigueredou
%%

\documentclass{sig-alternate}

\usepackage{algorithm}
\usepackage{algorithmic}

\begin{document}
%
% --- Author Metadata here --- \conferenceinfo{WOODSTOCK}{'97 El Paso,
%   Texas USA}
% \CopyrightYear{2007} % Allows default copyright year (200X) to be over-ridden - IF NEED BE.
% \crdata{0-12345-67-8/90/01} % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Evolved Neural Fields Applied to the Stability Problem of a
  Simple Biped Walking Model} \subtitle{[Track: Artificial Life,
  Evolutionary Robotics, Adaptive Behavior, Evolvable Hardware]}

\numberofauthors{2}

% \author{
% %   1st. author
%   \alignauthor
%   Juan Figueredo\\
%   \affaddr{Universidad Nacional de Colombia}\\
%   \affaddr{Ciudad Universitaria}\\
%   \affaddr{Bogotá, Colombia}\\
%   \email{jjfigueredou@unal.edu.co}
% %   2nd. author
%   \alignauthor
%   Jonatan Gómez\\
%   \affaddr{Universidad Nacional de Colombia}\\
%   \affaddr{Ciudad Universitaria}\\
%   \affaddr{Bogotá, Colombia}\\
%   \email{jgomezpe@unal.edu.co} }

\maketitle

\begin{abstract}
  The neural field model has the potential to address goal-based
  planning problems but has not been significantly applied to dynamic
  control problems. We propose a control architecture based on neural
  fields which is suitable to perform the control of a relatively
  complex and unstable system. We propose a strategy for the evolution
  of the kernel function for each population on the field. We test it
  over the stability problem on a typical inverted-pendulum and
  compare the performance of an evolved neural field and a hand-tuned
  neural field. There are presented some relevant requirements for the
  neural field controller architecture and its parameterization by
  evolution, and the controller architecture is detailed. The neural
  field controller performs well in the simulation and has a spatial
  representation which allows interpretation of field
  potentials. Also, the evolved neural field performs better than the
  non-evolved one, uses a different strategy to control the plant, and
  is able to recover fast from worst-case initial conditions.
\end{abstract}

\category{I.2.8}{Artificial Intelligence}{Problem Solving, Control
  Methods, and Search}[control theory]

\category{I.2.6}{Artificial Intelligence}{Learning}[connectionism and
neural nets]

\category{I.2.9}{Artificial Intelligence}{Robotics}[kinematics and
dynamics]

\terms{Algorithms, Design}

\keywords{Neural fields, neurocontrol, evolutionary robotics,
  artificial life}

\section{Introduction}
Artificial life aims to find those emergent phenomena that give
complex attributes to the existent living beings. In this work,
efforts are directed towards the study of emergence of motion control
capabilities and dynamical planning behaviors of biped walking
agents. Following the artificial life approach
\cite{Nolfi04Evolutionary}, those capabilities are expected to emerge
from a very simple or non-functional initialization, in this case
using a neural control architecture.

In biped robotics, the methods based on computational intelligence for
planning and control have shown to be able to achieve static stability
\cite{Kun97Adaptive}, dynamical stability
\cite{Nakanishi2004b,Komatsu05Dynamic}, achieve simple control
structures \cite{Huelse04Structure}, and tolerate perturbations
\cite{Juang02Intelligent}. Nonetheless, those properties have not been
extended to an integrated architecture of planning and control capable
of following goals.

Here is proposed a control scheme based on neural fields and a
comparison is made between a hand-tuned controller and a controller
parameterized by an evolutionary algorithm. As controllers, the neural
fields, compared with recurrent neural networks, have a deeper
biological basis, apply more restrictions and extend the discrete
model to a continuous one, following the method of planning and
control by means of neural fields \cite{Bergener99Complex}. The neural
field model, as noted in the article by Bergener et al., has the
potential to address goal-based planning problems, so we are here
interested on its capability to solve dynamic control problems.

The control problem set for testing the architectures is the stability
problem of an inverted pendulum, so that the controller ability to
perform dynamic control on an unstable plant can be evaluated. To the
authors' knowledge this is the first time neural fields parameterized
by evolutionary algorithms have been evaluated for solving a control
problem for an unstable plant.

First, some preliminaries on computational intelligence are presented,
mainly in the area of neural fields, which is the main focus of the
article, and in the area of evolutionary computation. In the remaining
sections the control problem used as test bed is detailed, the neural
field control architecture is presented and the strategies for its
manual parameterization and parameterization by evolution are shown,
the experimental results are presented, and finally, a discussion is
made.


\section{Preliminaries on Computational Intelligence}
\subsection{Neural Fields}
Artificial neural networks are a connectionist computing scheme
inspired by brain neural layout at cellular level. It is based on
simple computing structures called neurons which have several inputs
and a single output.

Recurrent neural networks present a dynamic behavior because of its
memory, that is, each state depends of the previous state in such a
way that a difference equation arises. There is not a notion of
locality in this model and the interactions between neurons and inputs
is given by parameter matrices.

Neural fields, on the other hand, arise as a tissue level model of
neural populations in brain. The model has been proposed by Wilson and
Cowan \cite{Wilson72Excitatory} and detailed by Amari
\cite{Amari77Dynamics} in the particular case of lateral
inhibition. In this model, neural population in considered a continuum
in which exists a dynamical evolution equation where the mean
activation potential evaluated in one place is affected by its
neighborhood, according to a so-called mexican hat function (as noted
by Coombes \cite{Coombes05Waves} better called wizard hat function),
in which close neighbors act as exciters and distant ones act as
inhibitors. Their mathematical formulation for the one-dimensional
case is:

\begin{equation}
  \label{eq:neuralfield}
  \frac{1}{\alpha}
  \dot{u}(x)=-u(x)-h+s(x)+\int_{-\infty}^{\infty}{w(x,x')\sigma(u(x'))dx'}
\end{equation}

Where $\alpha$ is a temporal constant of synaptic decay rate, $u(x)$
is the average membrane potential of the neurons located at position
$\psi$ at time $t$ (where $\psi$ is supposed to be 1-dimensional and
the time is omitted for readability). The average intensity of
connection from neurons at $\psi$ to neurons at $x'$ is modeled with
$w(x,x')$, $f(\cdot)$ is the saturating output function which is
monotonically nondecreasing. The deviation of the average stimulation
potential at place $\psi$ at time $t$ is represented by $s(x)$, and
$h=\bar{s}-r$ is the sum of the average stimulation potential an the
resting potential.

The main difference between recurrent neural networks and neural
fields is that, in the first, the relation among the neurons is
arbitrary and discrete, but in the second is continuous and is meant
to be related to locality. Besides, the first right hand element
assures and stable homogeneous behavior in the simplified linearized
form.

\subsection{Evolutionary algorithms}
Evolutionary algorithms are a set of population-based heuristic search
and optimization techniques. They maintain a population, and apply a
set of operators or transformations over its members. Those operators
are typically inspired on biological evolution and usually include
selection, reproduction and mutation, among others. The operators are
dependent of the evaluation of a performance function called fitness
function. Generally, fitness function evaluation may include, from a
simple numerical evaluation, to a complex simulation, in order to get
the performance criterion which its optimization is pursued.

The pseudo-code of a general evolutionary algorithm is as follows:

\algsetup{indent=2em}
\begin{algorithm}[h!]
  \caption{$Evolutionary Algorithm$}\label{alg:factorial}
  \begin{algorithmic}[1]
    \STATE $P \leftarrow$ Generate initial population of size $N$
    \STATE Evaluate fitness for each individual in $P$ \REPEAT \STATE
    $P' \leftarrow$ Apply operators to $P$ \STATE Evaluate fitness for
    each individual in $P'$ \STATE $P \leftarrow$ Select $N$
    individuals in $P'$ according to a selection scheme
    \UNTIL{Termination condition is met}
  \end{algorithmic}
\end{algorithm}

The most predominant form of an evolutionary algorithm is embodied by
genetic algorithms. They most frequent genotypical representation is a
bit sequence, although other representations can be used. Usually they
are implemented with a generational replacement of population, but in
some situations it is useful to conserve a small set of the better
individuals across generations in a steady-steady replacement.

\section{The Stability Problem Model}
\label{sec:model}

The model used consists of an approach to biped walking based on a
inverted pendulum (car-and-pole) system in which the pendulum
equilibrium is looked for. Nonetheless, supposing that the pendulum
mass represents the body center of mass, it is proposed that is
reasonable to expect a system with its sole function being to
stabilize the body. This way, if we where to devise a navigation
system, it would have as purpose to carefully perturb the first
controller in such a way that the stabilizing controller moves the car
to the desired position.

\subsection{Dynamic Model}
The dynamic model used, in mathematical terms, is expressed in the two
equations:

\begin{align}
  \label{eq:nf-simp}
  \ddot{x}&=\frac{F+ml\dot{\theta}^2\sin\theta-mg\cos\theta\sin\theta}{M+m\sin^2\theta}\\
  \ddot{\theta}&=\frac{(M+m)g\sin\theta-F\cos\theta-ml\dot{\theta}^2\sin\theta\cos\theta}{l(M+m\sin^2\theta)}+\frac{\tau}{ml^2}-\frac{\dot{\theta}}{2}
\end{align}
Where $x$ here is the linear position, $\theta$ is the angular
position, $M$ is the pendulum mass (located at the outer side), $m$ is
the cart mass, $l$ is the pendulum length and $g$ is the gravity
acceleration. It is included in the model a viscous friction for the
rotation.


This model consists of four state variables and a high non-linearity
as it departs from equilibrium points. It is worth noting that the
wanted equilibrium point is in fact unstable.


\section{Neural Fields for Control and Planning}

\subsection{Properties}
\label{sec:properties}
For the purpose of control and planning we need some particular
requirements on the neural fields.

The first one is to have a preprocessing over the input obtained from
the sensors, so that there is a closed loop where the representation
of inputs has an appropriate form. This mechanism alone (a particular
form for the inputs) has shown to be enough for the robot ARNOLD to
navigate in the plane with obstacles \cite{Bergener99Complex}.

The second one is to be able to modify the connection kernel so that
it can be suitable to complex control problem. In order to do that, we
will consider that the connection kernel $w(y)$ is a symmetric
function (i.e. $w(y)=w(-y)$), that also is a 2-power Lebesgue
integrable function so that it also belong to $L^2$. It can be shown
that, whit that definition, a sum of an arbitrary number of kernel
functions will also be a kernel function. This way, we have a
inner-product defined by the Lebesgue measure:

\begin{equation}
  \label{eq:eq-l2}
  \langle f,g \rangle_{L^2} = \int_{R}{f\cdot g d\mu}
\end{equation}

The defined space, whit its measure, conforms a Hilbert space, and
therefore is complete and metrizable. It also gives a notion of sum,
and scalar product:

\begin{eqnarray}
  \label{eq:eq-leb-opers}
  (f+g)(x)=&f(x)+g(x) \\
  (\lambda f)(x)=&\lambda f(x)
\end{eqnarray}

Those properties define and space with its operators which can be used
to apply an evolutionary algorithm, by evolving the kernel function of
the neural field.

The third one consists of its suitability to simulation. This is not
an inherent restriction for it to be physically (or biologically)
plausible, but to be implementable on a computer. We will take a
discrete form of the equation \ref{eq:nf-simp}:


\begin{equation}
  \label{eq:nf-disc}
  \tau \dot{u}_i=-u_i+\sum_{x_j \in B_p(x_i)} {w\left(x_i,x_j\right)
    f\left( u_j \right)}+S(x_i,t)
\end{equation}

Where we replace the integral for a sum over the point included inside
a finite neighborhood (ball) around $x_i$ with radius $p$. The time is
considered continuous, and the computation of the dynamical system
behavior is evaluated with a fourth-order Runge-Kutta method. We
denote $u_i=u(x_i,t)$. It should be noted that the previous equation
can be applied to the $n$-dimensional case without modification.

\subsection{Control Architecture}
The control architecture built based on the neural fields has three
basic elements.

The first one, is a sensor, which reads the states from the plant and
also their derivatives (computed from the dynamical equation of the
plant). In particular, the sensor used for the neural field controller
is rather simple, taking the values of the angular-related states
(i.e. angular position and angular velocity) as feedback.

The second one is the input layer, which consists of a simple neural
field without natural dynamics, where the spatial codification of the
sensed values is made. For the problem at hand, we use a finite
one-dimensional neural field, where a sensed input with value zero
maps to the center point of the field, and other values are
correspondingly coded in other (positive or negative)
positions. Angular position values are coded as local potentials with
value $u(x)=1$ and angular velocities as local potentials with value
$u(x)=k_\omega$, where $0 \le k_\omega < 1$. It is worth noting that
the sum between input states is performed directly by the neural field
dynamics.

The third one is the processing layer, which consists of a more
typical neural field which has inner dynamics given by the
eq. \ref{eq:nf-disc}, where the fields taken into the sum are the
input neural field, and the processing neural field. This way, besides
its natural dynamics, the processing layer receives the inputs from
the input field filtered by a kernel operator.

The parameterization of the controller is performed by varying the
kernel operator. For the hand-tuned case, the kernel operator used is
a Wizard Hat Function with the expression:

\begin{equation}
  \label{eq:wizard-hat}
  w(x_i,x_j)=ke^{-(x_i-x_j)^2/\delta^2}-H_0
\end{equation}

Where the diverse parameters work as vertical ($k$) and horizontal
($\delta$) scaling, and as vertical offset ($H_0$).

The kernel operator for the evolutionary-tuned case is evaluated with
the expression:

\begin{equation}
  w(x_i,x_j)=\mathtt{kernelArray}[|x_i-x_j|]
\end{equation}

Where \texttt{kernelArray} is the array of parameters modified by the
evolutionary algorithm. The kernel value is evaluated by accessing the
array at position $|x_i-x_j|$.

The additional term on the eq. \ref{eq:nf-disc} $S(x_i,t)$ is used
only as the uniform and static resting potential, that is
$S(x_i,t)=-r_p$.  The firing rate function $f(u_i)$ is simulated as a
simple Heaviside function.

The output is processed taking the position with highest activation on
the processing filtered by another wizard-hat function, and decoding
it to a value.

The figure \ref{fig:nf-controller} illustrates the input and output
layers (in the 2-dimensional case for generality) and the
participation on the potential of a single element in the processing
(or main) layer from the elements in the same layer and in the input
layer.


\begin{figure}[t]
  \label{fig:nf-controller}
  \centering \epsfig{file=fieldsGaussians.eps, width=7cm}
  \caption{Neural fields for stability control (feedback with the
    plant not shown).}
\end{figure}


\section{Evolution of Neural Field Controllers}
\subsection{Evolutionary Algorithm Structure and Parameters}
For the evolution process it is used a simple evolutionary algorithm
as shown in the preliminaries, with random elimination of individuals
inversely proportional with their fitness.

The evolution parameters are the connection kernels between the input
layer and the processing layer, and the recurrent connections of the
processing layer with itself. The connection kernels are considered
isotropic and homogeneous along the field, so that they can be
described as symmetric one-dimensional arrays of values.

\subsection{Genotypic Representation and Evolution Operators}
Each connection kernel can be represented as an array of $N$ values
from $w(0)$ to $w(p)$ with homogeneous spacing, using their
symmetry. This way, for an equal boundary radius for all the kernels,
and a 2-layered architecture, there are $2N$ real values in the
genotype. As can be seen, the number of evolution parameters does not
have a direct relation with the simulation size of the neural fields
(the number of discrete points used), in contradistinction with
recurrent neural networks, where the number of parameters depends on
the number $n$ of neurons with a polynomial order
$O(n^2)$. Nonetheless, here is taken a more general approach and the
boundary radius is set equal to $n$, so that there are $O(n)$
parameters.

The evolution operations used in both steps are:
\begin{itemize}
\item Parametric mutation of input array: Gaussian modification of
  real codified array values, which varies the connection kernel
  between input layer and processing layer.
\item Parametric mutation of recurrence array: Gaussian modification
  of real codified array values, which varies the recurrent connection
  kernel of the processing layer.
\item Selection: Calculates population fitness, selects with elitism
  and culling (5\% of both) couples of parents for generating new
  offsprings, calculates the fitness function for both offsprings.
\end{itemize}

The mutation operators implemented apply the sum operator defined in
eq. \ref{eq:eq-leb-opers} but there was not implemented a crossover
operator that used the scalar operator as it was not deemed necessary,
but can be easily implemented for another application if it is
considered useful.

\subsection{Fitness Function}
The fitness function is selected in such a way that the stability
controller mainly has the goal to reduce inclination. It was tuned
experimentally to attain a convergence velocity suitable for the
experiment. This has in mind a notion of sequential evolution of,
first, the capability to attain equilibrium, and later, the capability
to perturb the equilibrium controller in such a way that a planned
trajectory can be followed or a reference can be tracked. Here we are
interested only on the stability problem.

The fitness function for the stability controller is:

\begin{equation}
  F_1=100-\frac{100}{(\pi^4+2)T_{total}}\sum_t{\left(\theta(t) ^4+\frac{|x(t)|}{10}\right)}
\end{equation}

This fitness function aims to minimize the orientation error, but also
has as a minor second goal to minimize the total horizontal
displacement.

While the above expression was used to get the fitness value, the
actual fitness function includes running a simulation instance of the
control problem with a neural field controller grown from the two
kernel arrays.


\section{Experimental Results}
\subsection{Experimentation Details}
The sampling time used was $0.025$s (for neural fields, and
visualization) and were performed $10$s tests.

The differential equation system was solved by a fixed step numerical
method, a 4th Order Runge-Kutta. The iteration step selected was also
$h=0.025s$ for each test.

Here are shown the results for the proposed neural field architecture
with and without evolution (with an appropriate selection of
parameters for the non-evolved case). Also, for reference, it is
included the simulation of a controller omitting the processing layer
(direct controller), which is roughly equivalent to a simple state
space controller. The last controller does not need any additional
parameters aside the common ones.

For all the simulations, the initial angular position was
$\theta=\pi/6$, the number of discrete positions used in the
simulation of the neural field was $21$, and the angular position
$\theta$ was encoded into the input field with value $1$ while the
angular velocity $\omega$ was coded with value $k_\omega=0.5$. The
neural field time constant was taken with value $\tau=1/10$s. The
filtering (wizard hat) kernel on the actuator had values $k=1$,
$\delta=2$ and $H_0=0$.

For the non-evolved controller, it were used also wizard hat kernels
as defined in eq. \ref{eq:wizard-hat}. The input kernel had values
$k=2$, $\delta=2$ and $H_0=0.1$. The processing kernel had values
$k=0.3$, $\delta=2$ and $H_0=0.1$. Those values were derived mostly by
trial-and-error.

For the evolved controller, there were used parameterized kernels feed by
the kernel arrays on the genome of the evolutionary algorithm. The
Gaussian mutation operators were initialized with a standard deviation
of 0.3. Its application rate is evolved itself by the evolutionary
algorithm used, which was previously designed by professor Gómez
(Hybrid Adaptive Evolutionary Algorithm).

\subsection{Results}

The direct controller can by itself attain stability for the initial
value $\theta=\pi/6$ but the performance is poor. While not shown, it
has problems stabilizing the pendulum with an initial value of
$\theta=\pi/3$ or higher.

The hand-tuned controller is able to control the stability without
evolution with a better performance than the presented by the direct
controller. It can stabilize in the 10s time those instances with an
initial value of $\theta=\pi/3$ or higher. Nonetheless, it causes big
displacements and tends to keep a small but persistent orientation
error.

Finally, the evolved controller has the best performance of the three,
performs a fast stabilization of the pendulum even with an initial
value of $\theta=\pi$ (worst-case scenario for the initial
orientation), which is shown in figure \ref{fig:theta-pi}. It is the
only one that stays for long periods of time on the reference
orientation and it causes the least displacements. Despite its
parameterization being carried out by evolution, its strategy can be
understood by looking at processing field activation values, and this
controller seems to apply short burst of switching maximum values in a
close-to-optimal manner.


\begin{figure*}
  \centering \epsfig{file=neuralfield-panel-2.eps, width=14cm}
  \caption{System dynamics with an evolved Neural Field Controller, at
    time $t=4$. Left: trace of the pendulum (cart in blue and pole tip
    in red). Right: snapshot of the animation at time $t$.}
  \label{fig:theta-pi}
\end{figure*}

The three figures \ref{fig:inputs}, \ref{fig:processings} and
\ref{fig:pendulum-states} show the input fields, the processing fields
and the state variables evolution (respectively) for the three
controllers.

\begin{figure}
  \centering \epsfig{file=inputPopulation_old.eps, width=7cm,
    angle=-90} \epsfig{file=inputPopulation.eps, width=7cm, angle=-90}
  \epsfig{file=inputPopulation_evo.eps, width=7cm, angle=-90}
  \caption{Input layer activation for simulations between $t=0$s and
    $t=10$s with steps $h=1/40$s and positions between $x_{min}=-10$
    and $x_{max}=10$. First: direct (without processing layer)
    controller. Second: non-evolved controller. Third: evolved
    controller.}
  \label{fig:inputs}
\end{figure}

\begin{figure}
  \centering \epsfig{file=fieldPopulation_old.eps, width=7cm,
    angle=-90} \epsfig{file=fieldPopulation.eps, width=7cm, angle=-90}
  \epsfig{file=fieldPopulation_evo.eps, width=7cm, angle=-90}
  \caption{Processing layer activation for simulations between $t=0$s
    and $t=10$s with steps $h=1/40$s and positions between
    $x_{min}=-10$ and $x_{max}=10$. First: direct (without processing
    layer) controller, illustrative of field dynamics as it is
    excluded of the control action. Second: non-evolved
    controller. Third: evolved controller.}
  \label{fig:processings}
\end{figure}


\begin{figure}
  \centering \epsfig{file=pendulum_old.eps, width=7cm, angle=-90}
  \epsfig{file=pendulum.eps, width=7cm, angle=-90}
  \epsfig{file=pendulum_evo.eps, width=7cm, angle=-90}
  \caption{Pendulum simulation states with several neural field
    controllers between $t=0$s and $t=10$. Each state is coded with a
    position (so that the pendulum can be simulated as a field on its
    own) this way: $x$:0, $\theta$:1, $\dot{x}$:2,
    $\dot{\theta}$:3. It can be seen the little variation in the
    angular position ($\theta$). The discontinuity in $x$ is present
    because position wraps in the simulation so that $x=5$ is
    equivalent to $x=-5$. First: direct (without processing layer)
    controller. Second: non-evolved controller. Third: evolved
    controller.}
  \label{fig:pendulum-states}
\end{figure}



\section{Conclusions}
The neural field controller architecture is a bit complex (in its
implementation) and its simulation slightly costly, but has some
notable advantages. The first one is its ability to self-compensate
or, equivalently, the stability of its natural dynamics, which is
attained after the setup of few parameters. The second one is its
suitability to the problem at hand, being able to solve it with a good
performance for low and mid perturbations without evolution.

Although there was a need for parameter configuration to attain a good
performance, evolution was not strictly required because the small
number of parameters to setup: basically three parameters of the
kernel function and the resting potential of the field equation, a
number of parameters of constant order in relation to the number of
nodes (discrete potentials on the neural field). Nonetheless, the
evolved controller performed better than the other two, is more
general because eliminates the need for manual conscious
parameterization and allows the designer to specify more precisely the
performance measure desired.

It is worth noting that the neural field has a spatial representation
which allows interpretation of field potentials (as shown in
fig. \ref{fig:processings}). Indeed, its geometrical representation
allows for a small switch between a state-space like controller to a
neural field controller. The interpretation or understanding of
recurrent neural networks tends to be difficult and even more with
increasing states involved. This makes the neural field controller not
as black-box as the a recurrent neural network controller. This holds
even in the case of the evolved neural field controller.

More complex control problems could benefit from the strategy of
parameterization of neural field controllers by evolution here
developed. This way, it is left for future work the task of
integration of multiple goals in different populations and the design
of an arbitration scheme compatible with the architecture.

\bibliographystyle{abbrv} \bibliography{bibanot}

\end{document}
