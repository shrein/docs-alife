%\chapter{Neural Fields as Control and Planning Systems} \label{ch:chp2}
\section{Introduction} 
In this chapter we aim to propose a control planning system or
architecture based on neural fields which is suitable to control a
relatively complex system. We test it over the stability problem on a
typical inverted-pendulum and compare it against a more traditional
recurrent neural network controller. First, we present the neural
fields model, some variations of it which will be useful for its
evolution (detailed in next chapters) and some of the properties that
arise from it. Next, we study its applications to control and compare
it with the recurrent neural network control scheme. We briefly
compare its properties with traditional control schemes, and finally
we test it with the inverted-pendulum problem.

%\section{Goal-Based Planning and Control Planning}

\section{Neural Fields for Control and Planning}
For the purpose of control and planning we need some particular
requirements on the neural fields.

The first one is to have a preprocessing over the input
obtained from the sensors, so that there is a closed loop where the
representation of inputs has an appropriate form. This mechanism alone
(a particular form for the inputs) has shown to be enough for the robot
ARNOLD to navigate in the plane with obstacles
\cite{Bergener99Complex}.

The second one is to be able to modify the connection kernel so that
it can be suitable to our control problem. In order to do that, we
will consider that the connection kernel $w(y)$ is a symmetric
function (i.e. $w(y)=w(-y)$), that also is a 2-power Lebesgue
integrable function so that it also belong to $L^2$. It can be shown
that, with that definition, a sum of an arbitrary number of kernel
functions will also be a kernel function. This way, we have a
inner-product defined by the Lebesgue measure:

\begin{equation}
  \label{eq:eq-l2}
  \langle f,g \rangle_{L^2} = \int_{\mathbb{R}}{f\cdot g d\mu}
\end{equation}

The defined space, whit its measure, conforms a Hilbert space, and
therefore is complete and metrizable. It also gives a notion of sum,
and scalar product:
\begin{eqnarray}
  \label{eq:eq-leb-opers}
  (f+g)(x)=&f(x)+g(x) \\
  (\lambda f)(x)=&\lambda f(x)
\end{eqnarray}
Those properties will be used shortly when arises the problem
kernel evolution.

The third one consists of its suitability to simulation. This is not an
inherent restriction for it to be physically (or biologically)
plausible, but to be implementable on a computer. We will take a
discrete form of the equation \ref{eq:nf-simp}:


\begin{equation}
  \label{eq:nf-disc}
  \tau \dot{u}_i=-u_i+\sum_{x_j \in B_p(x_i)} {w\left(x_i,x_j\right)
    f\left( u_j \right)}+S(x_i,t)
\end{equation}

Where we replace the integral for a sum over the point included inside
a finite neighborhood (ball) around $x_i$ with radius $p$. The time is considered
continuous, and the computation of the dynamical system behavior is
evaluated with a Runge-Kutta method. We denote $u_i=u(x_i,t)$. It
should be noted that the previous equation can be applied to the
$n$-dimensional case without modification.

\section{Control Architecture}
The control architecture built based on the neural fields has three
basic elements. 

The first one, is a sensor, which reads the states
from the plant and also their derivatives (computed from the dynamical
equation of the plant). In particular, the sensor used for the neural
field controller is based on the angular acceleration of the pendulum
pole, loosely resembling the vestibular system on the inner ear.

The second one is the input layer, which consists of a simple neural
field without natural dynamics, where the spatial codification of the
sensed values is made. For the problem at hand, we use a
finite one-dimensional neural field, where a sensed input with value
zero maps to the center point of the field.

The third one is the processing layer, which has a more typical neural
field which has inner dynamics given by the eq. \ref{eq:nf-disc},
where the fields taken into the sum are the input neural field, and
the processing neural field. This way, besides its natural dynamics,
the processing layer receives the inputs from the input field filtered
by the kernel operator. The kernel operator used is a Wizard Hat
Function with the expression:

\begin{equation}
  w(x_i,x_j)=ke^{-(x_i-x_j)^2/\delta^2}-H_0
\end{equation}

The additional term on the eq. \ref{eq:nf-disc} $S(x_i,t)$ is used
only as the uniform and static resting potential, that is
$S(x_i,t)=-r_p$.
The firing rate function $f(u_i)$ is simulated as a simple Heaviside
function.

The figure \ref{fig:nf-controller} shows the input and output layers
(in the 2-dimensional case for generality) and the participation on
the potential of a single element in the processing layer from the
elements in the same layer and in the input layer.


\begin{figure}[t]
\label{fig:nf-controller}
\centering
\includegraphics[width=7cm]{fieldsGaussians.png}
\caption{Neural fields for stability control}
\end{figure}


\section{Evolution of Neural Fields}
\subsection{Neural Field Controller Architecture}
The architecture used for the neural field controller uses a structure
similar to that of multilayer perceptrons, i.e. an input layer, a
hidden layer and an output layer. The hidden layer has the properties
so far presented in the neural field model. The input and output layers are also
modelled as a population of neurons but without inner
dynamics. Nonetheless, it is used a kernel for the connection from the
input layer to the hidden layer, as well for the connection from the
hidden layer to the output layer.
The input layer is used as a buffer where sensory inputs are placed
before they are processed by the hidden layer. The output layer is
used so that it can be applied some form of post-processing to the
output of the hidden layer without changing the inner dynamics of the
neural field.

\subsection{Evolutionary Algorithm Structure and Parameters}
For the evolution process it is used a simple evolutionary algorithm
as shown in the preliminaries, with random elimination of individuals
inversely proportional with its fitness.

% , but with the addition of niching in the
% for of Deterministic Crowding (see \cite{referencia-dc}), in order to
% promote additional diversity and to prevent premature convergence.

The evolution parameters are the connection kernels between the input
layer and the hidden layer, and between the hidden layer and the
output layer. The recurrent connections of the hidden layer with
itself are left fixed, in the form of a wizard hat function.

The connection kernels are considered isotropic and homogeneous along
the field, so that they can be described as symmetric one-dimensional
arrays of values. 

\subsection{Genotypic Representation and Evolution Operators}
Each connection kernel can be represented as an array of $N$ values from
$w(0)$ to $w(p)$ with homogeneous spacing, using its symmetry. This
way, for an equal boundary radius for all the kernels, and a 3-layered
architecture, there are $3N$ real values in the genotype. As can be
seen, the number of evolution parameters does not have a direct
relation with the simulation size of the neural fields (the number of
discrete points used), in contradistinction with recurrent neural
networks, where the number of parameters depends on the
number $n$ of neurons with a polynomial order $O(n^2)$.

\subsection{Fitness Functions}
The fitness functions were selected in such a way that the stability controller
only has the goal to reduce inclination, while the positioning
controller has to take into account both inclination and position. The
fitness functions were tuned experimentally to attain a convergence
velocity suitable for the experiment. This has in mind a notion of
sequential evolution of, first, the capability to attain equilibrium,
and later, the capability to perturb the equilibrium controller in
such a way that a planned objective can be reached. 

The fitness function for the stability controller is:

\begin{equation}
F_1(\theta )=100-\frac{100\theta ^4}{\theta _{max}^4 T_{total}}
\end{equation}

And for the positioning controller is:

\begin{equation}
F_1(\theta ,e_x)=100-\frac{100(\theta ^4+e_x^4)}{(\theta _{max}^4+e_{x,max}^4) T_{total}}
\end{equation}


\section{Experimental Framework}
The model used consists of an approach to biped walking based on a
inverted pendulum (car-and-pole) system in which the pendulum equilibrium is looked
for. Nonetheless, supposing that the pendulum mass represents the body
center of mass, it is proposed that is reasonable to expect a system
with its sole function being to stabilize the body. This way, the
navigation system has as purpose to carefully perturb the first controller
in such a way that the stabilizing controller moves the car to the
desired position.

\subsection{Dynamic Model}
The dynamic model used, in mathematical terms, is expressed in the two
equations:

\begin{align}
\ddot{x}&=\frac{F+ml\dot{\theta}^2\sin\theta-mg\cos\theta\sin\theta}{M+m\sin^2\theta}\\
\ddot{\theta}&=\frac{(M+m)g\sin\theta-F\cos\theta-ml\dot{\theta}^2\sin\theta\cos\theta}{l(M+m\sin^2\theta)}+\frac{\tau}{ml^2}
\end{align} 

This model consists of four state variables and a high non-linearity
as it departs from equilibrium points. It is worth noting that the
wanted equilibrium point is in fact unstable.


\section{A RNN Approach for Comparison}
The proposed architecture for the recurrent neural network controller
has two expert recurrent networks, whose interaction will achieve
positioning and equilibrium as well.

There has been applied a preprocessing stage previous to the input
neurons, so that the actual values are not used and instead the inputs
are mapped to 3 fuzzy sets. In this way, the stability controller only
has 3 inputs, while the positioning controller has 6, corresponding to
the same 3 inputs previously described and another 3 due to the fuzzy
mapping of the error signal. All neurons are interconnected and the
first one of them is selected as output without loss of
generality. The neural network topology for the first controller
(stability) is shown in the figure \ref{fig:rnn-arch}.

\begin{figure}[t]
\label{rnn-arch}
\centering
\includegraphics[width=7cm]{rnn.png}
\caption{Neural net for stability control including fuzzy mapping}
\label{rnn}
\end{figure}

\subsection{Evolutionary Algorithm Structure for the RNN Controller}
It is expected, based on the approach of artificial life to
evolutionary robotics (Nolfi y Floreano), that the sequential and
cooperative evolution of elements with biological similarity leads to
an specialization in the process of stabilization and positioning
(despite the antagonistic individual goals of each controller because of the
interest of the positioning controller to maximize also the global
performance).

As said, the two steps are executed sequentially, taking the best
individual of the first step to collaborate with the individual
evolved in the second step. 

Aiming to obtain a fixed length representation and limit the problem
dimensionality, it is used a model of order $Q$ totally connected. Any
network with an order equal or lesser and with total or partial
connections can be represented by the proposed model, by the addition
of activating/deactivating elements for neurons and
connections. Therefore, individual are codified as: 

\begin{itemize}
 \item A bit sequence representing a serialization of an activation matrix
   $A_a$ of dimension $Q$-by-$Q$ which activates/deactivates a
   recurrent connection.
 \item A sequence of real numbers representing a serialization of
   matrices $W_a$ and $W_b$, of dimension $Q$-by-$Q$ and
   $Q$-by-$(m+1)$ respectively.
\end{itemize}

The $C$ matrix is not evolved because it is chosen arbitrarily only
one output (the first neuron). 

The evolution operations used in both steps are:
\begin{itemize}
 \item Parametric mutation of inputs: Gaussian modification of real
   codified matrix weights, which varies connection weights of inputs.
 \item Parametric mutation of recurrences: Gaussian modification of real
   codified matrix weights, which varies connection weights of recurrences.
 \item Selection: Calculates population fitness, selects with elitism
   and culling (5\% of both) couples of parents for generating new
   offsprings, calculates the fitness function for both offsprings.
\end{itemize}

The fitness functions used are the same presented for the neural field controller.

\section{Experimental Set-up}
\label{sec:setup}

The model used consists of an approach to biped walking based on a
inverted pendulum (car-and-pole) system in which the pendulum equilibrium is looked
for. Nonetheless, supposing that the pendulum mass represents the body
center of mass, it is proposed that is reasonable to expect a system
with its sole function being to stabilize the body. This way, the
navigation system has as purpose to carefully perturb the first controller
in such a way that the stabilizing controller moves the car to the
desired position. Here we are particularly interested only on the
stability problem and controller.

\subsection*{Dynamic Model}
The dynamic model used, in mathematical terms, is expressed in the two
equations:

\begin{align}
\ddot{x}&=\frac{F+ml\dot{\theta}^2\sin\theta-mg\cos\theta\sin\theta}{M+m\sin^2\theta}\\
\ddot{\theta}&=\frac{(M+m)g\sin\theta-F\cos\theta-ml\dot{\theta}^2\sin\theta\cos\theta}{l(M+m\sin^2\theta)}+\frac{\tau}{ml^2}
\end{align} 

This model consists of four state variables and a high non-linearity
as it departs from equilibrium points. It is worth noting that the
wanted equilibrium point is in fact unstable.

The output from the stability controller maps to the lateral force
$F$. The angular actuator with value $\tau$ is left to a value of
zero, to allow the plant to behave according to its natural dynamics
on the angular coordinate.


\section{Experimental Results}
\subsection*{Experimentation Details}
The sampling time used was 0.04s (for neural networks, neural fields, and
visualization) and were performed 20s tests.

The differential equation system was solved by a numerical method,
4th Order Runge-Kutta. The iteration step selected was $h=0.002s$ for
each test.

Here are shown the results for the proposed neural field architecture
without evolution and an appropriate selection of parameters (made
taking in account the self-stability of the neural fields and the time
constants of the plant), and the evolution of a recurrent neural
network of a recurrent neural network controller.

\subsection*{Results}
The first experiment tests the physical model using the recurrent
neural network controller without evolution, to see the natural dynamics of the system when the
controller is configured arbitrarily (in such a way that can be perceived
the need of the evolutionary algorithm for the recurrent neural
network controller). Results are shown in the figure
\ref{inestabilidad}. As can be seen, it is an unstable system in the
origin. Red dots represent the pendulum position referenced to
universal coordinates, and blue dots represent the base (car)
position.


\begin{figure}[t]
\centering
\includegraphics[width=7cm]{inestabilidadG.png}
\\
\includegraphics[width=7cm]{inestabilidadC.png}
\caption{System dynamics with an untrained controller}
\label{inestabilidad}
\end{figure}

After the first step of the algorithm, and once done the stability
controller evolution, it is shown the behavior withdrawing the
positioning controller in the figure \ref{final}. The evolution was performed with a population
of 50 individuals and 300 iterations.

\begin{figure}[t]
\centering
\includegraphics[width=7cm]{finalG.png}
\\
\includegraphics[width=7cm]{finalC.png}
\caption{System dynamics with a RNN controller trained.}
\label{final}
\end{figure}

On the other hand, when the initial angular perturbation is small, the
neural field is able to control the stability without evolution. The
simulation is shown in the figure \ref{estabilidad}.


\begin{figure}[t]
\centering
\includegraphics[width=7cm]{estabilidadG.png}
\\
\includegraphics[width=7cm]{estabilidadC.png}
\caption{System dynamics with a non-trained Neural Field Controller.}
\label{estabilidad}
\end{figure}

The output from the processing field can be seen in the figure
\ref{fig:nf-result}.


\begin{figure}[t]
\centering
\includegraphics[width=7cm]{camposC.png}
\caption{Processing Neural Field simulation.}
\label{estabilidad}
\end{figure}



\section{Discussion}
The results obtained from this chapter can be summarized in a short
analysis. 

While the recurrent neural network controller is expressive
enough to solve the problem at hand, the number of parameter to
configure (or in this case to evolve) is of a quadratic order in
relation to the number of nodes (or neurons). This were not a
particular problem for the evolutionary algorithm used, but limits its
potential scalability. Furthermore, while it is expressive enough,
does not show a particular suitability to the dynamic stability
problem of the inverted pendulum and there are no reasons to expect
something different for a more complex biped model. 

On the other hand, the neural field controller is a bit more complex
and its simulation more costly, but has some notable advantages. The
first one is its ability to self-compensate or, equivalently, the
stability of its natural dynamics, which is attained after the setup
of few parameters. The second one is it suitability to the problem at
hand, being able to solve it with a acceptable degree of performance
for small perturbations. Although there was a need to parameter
configuration, evolution was not required because the small number of
parameters to setup: basically three parameters of the kernel function
and the resting potential of the field equation - a number of
parameters of constant order in relation to the number of nodes (point potentials
on the neural field).

It is left for next chapters the challenging but promising task of
neural field evolution.









